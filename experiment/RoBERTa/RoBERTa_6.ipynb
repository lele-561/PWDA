{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGATf7zgfQDm"
      },
      "source": [
        "# Run PWDA Experiment on RoBERTa Model for Text Multi-Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzIYXTfbd9XD"
      },
      "outputs": [],
      "source": [
        "!pip install -U simpletransformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-q_SCpad9nS"
      },
      "outputs": [],
      "source": [
        "from simpletransformers.classification import ClassificationModel\n",
        "import pandas as pd\n",
        "import logging\n",
        "import sklearn\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)\n",
        "\n",
        "args = {\n",
        "   'num_train_epochs': 4,\n",
        "   'train_batch_size': 16,\n",
        "   'max_seq_length': 128,\n",
        "   'overwrite_output_dir': True\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_file_normal = 'test.txt'\n",
        "eval_file_ocr = 'textflint-Ocr-test.txt'\n",
        "eval_file_insertAdv = 'textflint-InsertAdv-test.txt'\n",
        "eval_df_normal = []\n",
        "eval_df_ocr = []\n",
        "eval_df_insertAdv = []\n",
        "\n",
        "with open(eval_file_normal, 'r', encoding='UTF-8') as test_f_normal:\n",
        "    test_lines = test_f_normal.readlines()\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    for _ in test_lines:\n",
        "        parts = _.strip().split('\\t')\n",
        "        sentence = parts[0]\n",
        "        label = int(parts[1])\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "    eval_df_normal = pd.DataFrame({'text': sentences, 'labels': labels})\n",
        "\n",
        "# 测试集处理：ocr测试集\n",
        "with open(eval_file_ocr, 'r', encoding='UTF-8') as test_f_ocr:\n",
        "    test_lines = test_f_ocr.readlines()\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    for _ in test_lines:\n",
        "        parts = _.strip().split('\\t')\n",
        "        sentence = parts[0]\n",
        "        label = int(parts[1])\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "    eval_df_ocr = pd.DataFrame({'text': sentences, 'labels': labels})\n",
        "\n",
        "# 测试集处理：insertAdv测试集\n",
        "with open(eval_file_insertAdv, 'r', encoding='UTF-8') as test_f_insertAdv:\n",
        "    test_lines = test_f_insertAdv.readlines()\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    for _ in test_lines:\n",
        "        parts = _.strip().split('\\t')\n",
        "        sentence = parts[0]\n",
        "        label = int(parts[1])\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "    eval_df_insertAdv = pd.DataFrame({'text': sentences, 'labels': labels})"
      ],
      "metadata": {
        "id": "5VJy9-ni_X-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5ButGYMMaiG"
      },
      "outputs": [],
      "source": [
        "dataset = 'TREC-6'\n",
        "aug_num = [1, 2, 4, 8, 16]\n",
        "all_num = [100, 500, 2000, 3569]\n",
        "alphas = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "operations = ['RP', 'RI', 'RS', 'RD']\n",
        "\n",
        "mcc_list_normal = []\n",
        "mcc_list_ocr = []\n",
        "mcc_list_insertAdv = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    for operation in operations:\n",
        "        for all in all_num:\n",
        "            for _ in aug_num:\n",
        "                train_dir = 'pwda-' + str(alpha)\n",
        "                train_file = train_dir + '/' + 'pwda-train-' + str(alpha) + '_' + operation + '_' + str(\n",
        "                    all) + '_' + str(_) + '.txt'\n",
        "                train_df = []\n",
        "\n",
        "                # 训练集处理\n",
        "                with open(train_file, 'r', encoding='UTF-8') as train_f:\n",
        "                    train_lines = train_f.readlines()\n",
        "                    sentences = []\n",
        "                    labels = []\n",
        "                    for _ in train_lines:\n",
        "                        parts = _.strip().split('\\t')\n",
        "                        sentence = parts[0]\n",
        "                        label = int(parts[1])\n",
        "                        sentences.append(sentence)\n",
        "                        labels.append(label)\n",
        "                    train_df = pd.DataFrame({'text': sentences, 'labels': labels})\n",
        "                # 创建模型\n",
        "                model = ClassificationModel('roberta', 'roberta-base', num_labels=6, args=args)\n",
        "                # 训练模型\n",
        "                model.train_model(train_df)\n",
        "                # 验证模型\n",
        "                result_normal, model_outputs, wrong_predictions = model.eval_model(eval_df_normal, acc=sklearn.metrics.accuracy_score)\n",
        "                result_ocr, model_outputs, wrong_predictions = model.eval_model(eval_df_ocr, acc=sklearn.metrics.accuracy_score)\n",
        "                result_insertAdv, model_outputs, wrong_predictions = model.eval_model(eval_df_insertAdv, acc=sklearn.metrics.accuracy_score)\n",
        "                # 计算MCC\n",
        "                print(train_file)\n",
        "                print(result_normal['mcc'], result_ocr['mcc'], result_insertAdv['mcc'])\n",
        "                mcc_list_normal.append(result_normal['mcc'])\n",
        "                mcc_list_ocr.append(result_ocr['mcc'])\n",
        "                mcc_list_insertAdv.append(result_insertAdv['mcc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOU3ltUJF7K8"
      },
      "outputs": [],
      "source": [
        "mcc_list_normal"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcc_list_ocr"
      ],
      "metadata": {
        "id": "0Fs8dL5V98Jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcc_list_insertAdv"
      ],
      "metadata": {
        "id": "docX9Iyq975I"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
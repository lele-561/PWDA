{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGATf7zgfQDm"
      },
      "source": [
        "# Run PWDA Experiment on XLNet Model for Text Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wzIYXTfbd9XD"
      },
      "outputs": [],
      "source": [
        "!pip install -U simpletransformers "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-q_SCpad9nS"
      },
      "outputs": [],
      "source": [
        "from simpletransformers.classification import ClassificationModel\n",
        "import pandas as pd\n",
        "import logging\n",
        "import sklearn\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)\n",
        "\n",
        "args = {\n",
        "    'num_train_epochs': 4,\n",
        "    'train_batch_size': 16,\n",
        "    'max_seq_length': 128,\n",
        "    'overwrite_output_dir': True}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5VJy9-ni_X-Q"
      },
      "outputs": [],
      "source": [
        "eval_file_normal = 'test.txt'\n",
        "eval_file_ocr = 'textflint-Ocr-test.txt'\n",
        "eval_file_insertAdv = 'textflint-InsertAdv-test.txt'\n",
        "eval_df_normal = []\n",
        "eval_df_ocr = []\n",
        "eval_df_insertAdv = []\n",
        "\n",
        "# 测试集处理：常规测试集\n",
        "with open(eval_file_normal, 'r', encoding='UTF-8') as test_f_normal:\n",
        "    test_lines = test_f_normal.readlines()\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    for _ in test_lines:\n",
        "        parts = _.strip().split('\\t')\n",
        "        sentence = parts[0]\n",
        "        label = int(parts[1])\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "    eval_df_normal = pd.DataFrame({'text': sentences, 'labels': labels})\n",
        "\n",
        "# 测试集处理：ocr测试集\n",
        "with open(eval_file_ocr, 'r', encoding='UTF-8') as test_f_ocr:\n",
        "    test_lines = test_f_ocr.readlines()\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    for _ in test_lines:\n",
        "        parts = _.strip().split('\\t')\n",
        "        sentence = parts[0]\n",
        "        label = int(parts[1])\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "    eval_df_ocr = pd.DataFrame({'text': sentences, 'labels': labels})\n",
        "\n",
        "# 测试集处理：insertAdv测试集\n",
        "with open(eval_file_insertAdv, 'r', encoding='UTF-8') as test_f_insertAdv:\n",
        "    test_lines = test_f_insertAdv.readlines()\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    for _ in test_lines:\n",
        "        parts = _.strip().split('\\t')\n",
        "        sentence = parts[0]\n",
        "        label = int(parts[1])\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "    eval_df_insertAdv = pd.DataFrame({'text': sentences, 'labels': labels})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "r5ButGYMMaiG"
      },
      "outputs": [],
      "source": [
        "dataset = 'SST-2'  # 或CR\n",
        "aug_num = [1, 2, 4, 8, 16]\n",
        "alphas = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "operations = ['RP', 'RI', 'RS', 'RD']\n",
        "all_num = [100, 500, 2000, 5484] if dataset == 'SST-2' else [100, 500, 1472]\n",
        "\n",
        "f1_list_normal = []\n",
        "f1_list_ocr = []\n",
        "f1_list_insertAdv = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    for operation in operations:\n",
        "        for all in all_num:\n",
        "            for _ in aug_num:\n",
        "                train_dir = 'pwda-' + str(alpha)\n",
        "                train_file = train_dir + '/' + 'pwda-train-' + str(alpha) + '_' + operation + '_' + str(\n",
        "                    all) + '_' + str(_) + '.txt'\n",
        "                train_df = []\n",
        "\n",
        "                # 训练集处理\n",
        "                with open(train_file, 'r', encoding='UTF-8') as train_f:\n",
        "                    train_lines = train_f.readlines()\n",
        "                    sentences = []\n",
        "                    labels = []\n",
        "                    for _ in train_lines:\n",
        "                        parts = _.strip().split('\\t')\n",
        "                        sentence = parts[0]\n",
        "                        label = int(parts[1])\n",
        "                        sentences.append(sentence)\n",
        "                        labels.append(label)\n",
        "                    train_df = pd.DataFrame({'clean_text': sentences, 'target': labels})\n",
        "\n",
        "                # 创建模型\n",
        "                model = ClassificationModel('xlnet', 'xlnet-base-cased', args=args)\n",
        "                # 训练模型\n",
        "                model.train_model(train_df)\n",
        "                # 验证模型\n",
        "                result_normal, model_outputs, wrong_predictions = model.eval_model(eval_df_normal, acc=sklearn.metrics.accuracy_score)\n",
        "                result_ocr, model_outputs, wrong_predictions = model.eval_model(eval_df_ocr, acc=sklearn.metrics.accuracy_score)\n",
        "                result_insertAdv, model_outputs, wrong_predictions = model.eval_model(eval_df_insertAdv, acc=sklearn.metrics.accuracy_score)\n",
        "                # 计算F1值\n",
        "                recall_normal = result_normal['tp'] / (result_normal['tp'] + result_normal['fn'])\n",
        "                precision_normal = result_normal['tp'] / (result_normal['tp'] + result_normal['fp'])\n",
        "                f1_normal = 2 * precision_normal * recall_normal / (precision_normal + recall_normal)\n",
        "                f1_list_normal.append(f1_normal)\n",
        "                recall_ocr = result_ocr['tp'] / (result_ocr['tp'] + result_ocr['fn'])\n",
        "                precision_ocr = result_ocr['tp'] / (result_ocr['tp'] + result_ocr['fp'])\n",
        "                f1_ocr = 2 * precision_ocr * recall_ocr / (precision_ocr + recall_ocr)\n",
        "                f1_list_ocr.append(f1_ocr)\n",
        "                recall_insertAdv = result_insertAdv['tp'] / (result_insertAdv['tp'] + result_insertAdv['fn'])\n",
        "                precision_insertAdv = result_insertAdv['tp'] / (result_insertAdv['tp'] + result_insertAdv['fp'])\n",
        "                f1_insertAdv = 2 * precision_insertAdv * recall_insertAdv / (precision_insertAdv + recall_insertAdv)\n",
        "                f1_list_insertAdv.append(f1_insertAdv)\n",
        "                # 打印结果\n",
        "                print(train_file)\n",
        "                print(f1_normal, f1_ocr, f1_insertAdv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOU3ltUJF7K8"
      },
      "outputs": [],
      "source": [
        "f1_list_normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wweBaTuBZhG"
      },
      "outputs": [],
      "source": [
        "f1_list_ocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuBjTB5-BZay"
      },
      "outputs": [],
      "source": [
        "f1_list_insertadv"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}